{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d536d1af-44fd-471d-995d-8380de04c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "758a27de-1280-48ac-8439-0d4915891c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-5.0.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<2.0,>=1.3.0 (from transformers)\n",
      "  Downloading huggingface_hub-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typer-slim (from transformers)\n",
      "  Downloading typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2024.6.1)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.27.0)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer-slim->transformers) (8.1.7)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.14.0)\n",
      "Downloading transformers-5.0.0-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.6/10.1 MB 15.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.0/10.1 MB 14.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.2/10.1 MB 15.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 14.1 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-1.4.0-py3-none-any.whl (553 kB)\n",
      "   ---------------------------------------- 0.0/553.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 553.2/553.2 kB 19.4 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 13.3 MB/s eta 0:00:00\n",
      "Downloading typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/2.9 MB 14.1 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Installing collected packages: shellingham, safetensors, hf-xet, typer-slim, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed hf-xet-1.2.0 huggingface-hub-1.4.0 safetensors-0.7.0 shellingham-1.5.4 tokenizers-0.22.2 transformers-5.0.0 typer-slim-0.21.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts hf.exe and tiny-agents.exe are installed in 'C:\\Users\\Dhanalaxmi\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers.exe is installed in 'C:\\Users\\Dhanalaxmi\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1304d7e-135f-4156-934e-4418ffef078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\dhanalaxmi\\appdata\\roaming\\python\\python312\\site-packages (2.10.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.25.0-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.10.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dhanalaxmi\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torchvision-0.25.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 2.4/4.3 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.10.0-cp312-cp312-win_amd64.whl (475 kB)\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "Successfully installed torchaudio-2.10.0 torchvision-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd5e54b-b478-4d20-87c7-34ac78350b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dhanalaxmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dhanalaxmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Dhanalaxmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1505b72-b54c-4c3e-9d5e-f532c95b1692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3     Suresh Narayanasamy                       Fair   \n",
       "4               ASHIK P A                Over priced   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3     Certified Buyer, Chennai      25.0         1.0       NaN   \n",
       "4                          NaN     147.0        24.0  Apr 2016   \n",
       "\n",
       "                                         Review text  Ratings  \n",
       "0  Nice product, good quality, but price is now r...        4  \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3  Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f457cb29-aca7-4dec-8cb3-b836455ff427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8013, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de568ade-0a24-4f98-88af-6685005bae2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review text  Ratings\n",
       "0  Nice product, good quality, but price is now r...        4\n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1\n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1\n",
       "3  Quite O. K. , but nowadays  the quality of the...        3\n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only required columns\n",
    "df1= df[['Review text', 'Ratings']]\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e3707ce-371d-4895-8dcf-702fed329adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 5, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ratings'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d98805-6877-441e-b35b-ed6aec57ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Sentiment labels\n",
    "def label_sentiment(rating):\n",
    "    return 1 if rating >= 4 else 0\n",
    "\n",
    "df['sentiment'] = df['Ratings'].apply(label_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035cd757-7e36-4519-a962-729d0f9b1ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baji Sankar</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>173.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Oct 2018</td>\n",
       "      <td>Good quality product. Delivered on time.READ MORE</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Certified Buyer, Doom Dooma</td>\n",
       "      <td>403.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Jan 2020</td>\n",
       "      <td>BEST PURCHASE It is a good quality and is more...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "5             Baji Sankar      Mind-blowing purchase   \n",
       "6       Flipkart Customer                  Must buy!   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "5   Certified Buyer, Hyderabad     173.0        45.0  Oct 2018   \n",
       "6  Certified Buyer, Doom Dooma     403.0       121.0  Jan 2020   \n",
       "\n",
       "                                         Review text  Ratings  sentiment  \n",
       "0  Nice product, good quality, but price is now r...        4          1  \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1          0  \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1          0  \n",
       "5  Good quality product. Delivered on time.READ MORE        5          1  \n",
       "6  BEST PURCHASE It is a good quality and is more...        5          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fc5c3cc-59ca-4f13-843b-85f2052b0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Cleaning and Normalization\n",
    "#\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # remove special characters\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['clean_text'] = df['Review text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a844d744-fc83-4496-a83f-013fcb7652fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of Words(BoW)\n",
    "bow_vectorizer = CountVectorizer(max_features=5000)\n",
    "X_bow = bow_vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "y = df['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bfb3701-4cb6-439a-b4eb-79baa2741518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['clean_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fe8045c-f0a9-4dfd-934d-e873e5881c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2Vec\n",
    "tokenized_reviews = [text.split() for text in df['clean_text']]\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=tokenized_reviews,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "def get_w2v_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "X_w2v = np.array([\n",
    "    get_w2v_vector(tokens, w2v_model)\n",
    "    for tokens in tokenized_reviews\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e43485d-d05e-4ec2-b832-c70696db7a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349bff728c874693b1b675b38bbd6232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: bert-base-uncased\n",
      "Key                                        | Status     |  | \n",
      "-------------------------------------------+------------+--+-\n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED |  | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED |  | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED |  | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED |  | \n",
      "cls.seq_relationship.weight                | UNEXPECTED |  | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED |  | \n",
      "cls.predictions.bias                       | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "#Bert\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def bert_embeddings(text_list):\n",
    "    embeddings = []\n",
    "\n",
    "    for text in text_list:\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        embeddings.append(cls_embedding)\n",
    "\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_bert = bert_embeddings(df['clean_text'][:500])  # limit for speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51938813-fee1-48b5-b064-f8ef169571d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0942089c-67cd-4846-9bbd-c338597dd8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e743620a-dbe9-48c0-9453-8357bce464a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Linear SVM\": LinearSVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8afa810d-ad1e-4e7b-b42e-b6cf3cb41173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "F1-Score: 0.9054054054054054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73        28\n",
      "           1       0.88      0.93      0.91        72\n",
      "\n",
      "    accuracy                           0.86       100\n",
      "   macro avg       0.84      0.80      0.82       100\n",
      "weighted avg       0.86      0.86      0.86       100\n",
      "\n",
      "\n",
      "Linear SVM\n",
      "F1-Score: 0.896551724137931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.73        28\n",
      "           1       0.89      0.90      0.90        72\n",
      "\n",
      "    accuracy                           0.85       100\n",
      "   macro avg       0.82      0.81      0.81       100\n",
      "weighted avg       0.85      0.85      0.85       100\n",
      "\n",
      "\n",
      "Random Forest\n",
      "F1-Score: 0.8767123287671232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.67        28\n",
      "           1       0.86      0.89      0.88        72\n",
      "\n",
      "    accuracy                           0.82       100\n",
      "   macro avg       0.78      0.77      0.77       100\n",
      "weighted avg       0.82      0.82      0.82       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results= {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    results[name] = f1\n",
    "    \n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"F1-Score:\", f1)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c94f91b-ca03-4084-bcd5-f252fe960b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.905405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.876712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  F1-Score\n",
       "0  Logistic Regression  0.905405\n",
       "1           Linear SVM  0.896552\n",
       "2        Random Forest  0.876712"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"TF-IDF\")\n",
    "results_df = pd.DataFrame(\n",
    "    results.items(), columns=[\"Model\", \"F1-Score\"]\n",
    ").sort_values(by=\"F1-Score\", ascending=False)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74d3ed14-4acd-4715-949d-2044d5702c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_bow, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b8d40d0-ca3b-489d-8ff8-b773e95d55db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "F1-Score: 0.9233027522935779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.44      0.57       310\n",
      "           1       0.88      0.97      0.92      1293\n",
      "\n",
      "    accuracy                           0.87      1603\n",
      "   macro avg       0.84      0.71      0.74      1603\n",
      "weighted avg       0.86      0.87      0.85      1603\n",
      "\n",
      "\n",
      "Linear SVM\n",
      "F1-Score: 0.916728624535316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.47      0.57       310\n",
      "           1       0.88      0.95      0.92      1293\n",
      "\n",
      "    accuracy                           0.86      1603\n",
      "   macro avg       0.80      0.71      0.74      1603\n",
      "weighted avg       0.85      0.86      0.85      1603\n",
      "\n",
      "\n",
      "Random Forest\n",
      "F1-Score: 0.921415270018622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.50      0.60       310\n",
      "           1       0.89      0.96      0.92      1293\n",
      "\n",
      "    accuracy                           0.87      1603\n",
      "   macro avg       0.81      0.73      0.76      1603\n",
      "weighted avg       0.86      0.87      0.86      1603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results= {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    results[name] = f1\n",
    "    \n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"F1-Score:\", f1)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "321b68df-a8ae-4554-9c40-1e908b773d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.923303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.921415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.916729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  F1-Score\n",
       "0  Logistic Regression  0.923303\n",
       "2        Random Forest  0.921415\n",
       "1           Linear SVM  0.916729"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Bag of Words\")\n",
    "results_df = pd.DataFrame(\n",
    "    results.items(), columns=[\"Model\", \"F1-Score\"]\n",
    ").sort_values(by=\"F1-Score\", ascending=False)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d90b355-3240-4227-9d7b-3e0e7f440e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_w2v, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bb84fdf-1bc7-4e56-87ba-46245ae27bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "F1-Score: 0.8929558011049724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       310\n",
      "           1       0.81      1.00      0.89      1293\n",
      "\n",
      "    accuracy                           0.81      1603\n",
      "   macro avg       0.40      0.50      0.45      1603\n",
      "weighted avg       0.65      0.81      0.72      1603\n",
      "\n",
      "\n",
      "Linear SVM\n",
      "F1-Score: 0.892573402417962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       310\n",
      "           1       0.81      1.00      0.89      1293\n",
      "\n",
      "    accuracy                           0.81      1603\n",
      "   macro avg       0.40      0.50      0.45      1603\n",
      "weighted avg       0.65      0.81      0.72      1603\n",
      "\n",
      "\n",
      "Random Forest\n",
      "F1-Score: 0.9068100358422939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.25      0.38       310\n",
      "           1       0.85      0.98      0.91      1293\n",
      "\n",
      "    accuracy                           0.84      1603\n",
      "   macro avg       0.79      0.61      0.64      1603\n",
      "weighted avg       0.82      0.84      0.80      1603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    results[name] = f1\n",
    "    \n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"F1-Score:\", f1)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c609511-e504-4f92-839b-9a57d98c85df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.906810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.892956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.892573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  F1-Score\n",
       "2        Random Forest  0.906810\n",
       "0  Logistic Regression  0.892956\n",
       "1           Linear SVM  0.892573"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Word2Vec\")\n",
    "results_df = pd.DataFrame(\n",
    "    results.items(), columns=[\"Model\", \"F1-Score\"]\n",
    ").sort_values(by=\"F1-Score\", ascending=False)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c117fdd0-a032-455d-ad58-8e132e8f2b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score (Word2Vec + SVM): 0.892573402417962\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_w2v, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"F1-Score (Word2Vec + SVM):\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6298b51a-4ff3-4d00-93d5-90abeb8ec988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score (BERT): 0.9054054054054054\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_bert_scaled, y[:len(X_bert)], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"F1-Score (BERT):\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd1e594f-a505-4104-ad8b-d4dba394e053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score (Bert + SVM): 0.8873239436619719\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"F1-Score (Bert + SVM):\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb31cbc-e4f9-4c52-bb79-2d7916f1d831",
   "metadata": {},
   "source": [
    "For deployment, I selected TF-IDF with Logistic Regression as it achieved the highest F1-score while being computationally efficient, interpretable, and ideal for real-time sentiment analysis systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d747f040-c682-432b-9974-0561a95371c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score (BERT): 0.9223512336719883\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_bert_scaled = scaler.fit_transform(X_bert)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"F1-Score (BERT):\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "834775fd-d4f8-4315-8d55-b5f25642dd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(tfidf_vectorizer, \"tfidf.pkl\")\n",
    "joblib.dump(lr, \"sentiment_model.pkl\")\n",
    "print(\"Successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a59e81-327b-498c-85d5-ebf4def9e4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
